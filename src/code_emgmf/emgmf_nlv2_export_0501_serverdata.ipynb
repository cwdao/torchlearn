{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 张老师新给损失函数实现\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载各种包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "# from sklearn.preprocessing import label_binarize\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn import tree \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import scipy.io as scio\n",
    "# import hiddenlayer as h\n",
    "from visdom import Visdom\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchsummary import summary\n",
    "from torchviz import make_dot\n",
    "\n",
    "import datetime\n",
    "import os \n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "# from utils.reuse import *\n",
    "# from utils.networks import *\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device=torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 选择要加载的文件\n",
    "步骤如下：\n",
    "### 文件存储的路径解释\n",
    "/data/rmgmf_0430/:存储着所有数据集，文件名末尾的数字表示数据量，例如EMGSKdata-220426-slim_400.npy 表示这是降采样到 400 数据点的数据集。\n",
    "/src/model/: 存储所有模型相关的文件。\n",
    "### 模型文件举例说明\n",
    "`/src/model/emgmk_cnn_0410_nl/`为第一个模型的存储路径，对应数据集为 400 的数据；\n",
    "此目录下有数个文件，一般是两个，按生成时间先后，早一点的是不带 new loss 的纯 MSE 损失模型，晚一点的是带 newloss 的模型。注意区分。\n",
    "如果其他模型的文件夹内多于两个（如`emgmk_cnn_0410_nl_2`有3个），只看最新的两个文件，删除旧的，剩下的两个最新的同上区分方法。\n",
    "`/src/model/emgmk_cnn_0410_nl/vislog/`: visdom 日志，暂时不需要处理；\n",
    "`/src/model/emgmk_cnn_0410_nl/vislog/ckp/`:训练记录点，暂时不需要，我已经删除这一文件夹\n",
    "### 加载与运行说明\n",
    "1.加载数据与模型\n",
    "下面的代码中，`dataarray = np.load('../data/emgmf_0430/EMGSKdata-220426-slim_400.npy',allow_pickle=True)`填入本次的数据集，\n",
    "`checkpoint_for_net2 = torch.load('./model/emgmk_cnn_0410_nl/'+'kmmf_final__2022_04_30_21_34_48.pth')`填入本次的模型。\n",
    "\n",
    "2.运行所有代码至最后一个代码块之前。\n",
    "\n",
    "3.结果展示部分，修改`show_l`与测试集大小匹配，测试集大小可查看数据集加载部分代码块的第一行输出，例如`(480, 1) (120, 1)`，120就是要设成 `show_l`的数字\n",
    "\n",
    "4.重复`column`0~5，每次记录输出的图的RMSE值，放到一个excel里，即`结果记录.xlsx`\n",
    "\n",
    "5.在最后一个代码块`io.savemat('../data/data_400_mse.mat', {'variables': adataset_kmmf})`里设置本次的存储文件名称。记得对应数据集修改文件名。同时MSE的模型后面要标记_mse 以做区分\n",
    "\n",
    "6.结束，后续绘图工作转至matlab进行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataarray = np.load(\n",
    "    \"../data/WristDataForPINN-1/EMGSKdata-220422-slim.npy\", allow_pickle=True\n",
    ")\n",
    "# MSE\n",
    "# checkpoint_for_net2 = torch.load(model_Dir+'emgsk_upper200_oMSE_2022_04_25_20_39_01.pth')\n",
    "# newloss\n",
    "checkpoint_for_net2 = torch.load(\n",
    "    \"./model/emgmk_cnn_0410_nl/\" + \"ckp//\" + \"emgsk_ep_900_2022_04_25_20_39_01.pth\",\n",
    "    map_location=\"cuda:0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义神经网络结构\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [1, 128, 1, 6]           1,280\n",
      "            Linear-2                   [1, 128]          98,432\n",
      "            Linear-3                   [1, 128]          16,512\n",
      "            Linear-4                     [1, 6]             774\n",
      "================================================================\n",
      "Total params: 116,998\n",
      "Trainable params: 116,998\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.45\n",
      "Estimated Total Size (MB): 0.45\n",
      "----------------------------------------------------------------\n",
      "Outputshape: torch.Size([1, 6])\n"
     ]
    }
   ],
   "source": [
    "# 自定义神经网络,CNN\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "\n",
    "# hdreshape = 32*1*3\n",
    "# hdreshape = 2\n",
    "# hdlayer_1 = 16\n",
    "# hdlayer_2 = 16\n",
    "# hdlayer_3 = 256\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=128, kernel_size=3, padding=1\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, padding=1\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, padding=0\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=128 * 1 * 6, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=128)\n",
    "        # self.fc3 = nn.Linear(in_features=hdlayer_2, out_features=hdlayer_3)\n",
    "        self.out = nn.Linear(in_features=128, out_features=6)\n",
    "        self.dr1 = nn.Dropout2d(0.2)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "        # t = t.reshape(1,1,3)\n",
    "        # t = t.unsqueeze(0)\n",
    "\n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "        # t = F.max_pool2d(t, kernel_size=2, stride=1)\n",
    "\n",
    "        # (3) hidden conv layer\n",
    "        # t = self.conv2(t)\n",
    "        # t = F.relu(t)\n",
    "        # t = self.dr1(t)\n",
    "        # t = F.max_pool2d(t, kernel_size=2, stride=1)\n",
    "\n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 128 * 1 * 6)\n",
    "        # t = t.flatten(start_dim=0)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "        # t = self.fc3(t)\n",
    "        # t = F.relu(t)\n",
    "        # t = self.dr1(t)\n",
    "\n",
    "        # (5) output layer\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t\n",
    "\n",
    "\n",
    "net = Network()\n",
    "# 打印网络，检查输入输出 shape是否正确\n",
    "# print(net)\n",
    "samplebatchsize = 1\n",
    "summary(net, (1, 1, 6), batch_size=samplebatchsize, device=\"cpu\")\n",
    "sampleInput = torch.randn(samplebatchsize, 1, 1, 6).requires_grad_(True)\n",
    "sampleOutput = net(sampleInput)\n",
    "print(\"Outputshape:\", sampleOutput.shape)\n",
    "# framevision = make_dot(sampleOutput, params=dict(list(net.named_parameters()) + [('x',sampleInput)]))\n",
    "# framevision.format = \"png\"\n",
    "# framevision.direcory = \"./\"\n",
    "# framevision.view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据集加载、构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "(160, 1) (40, 1)\n",
      "torch.Size([160, 6]) torch.Size([160, 6]) torch.Size([40, 6]) torch.Size([40, 6])\n"
     ]
    }
   ],
   "source": [
    "CNNdataset = dataarray.item()\n",
    "print(type(CNNdataset))\n",
    "# 加载自变量：因为数据头尾不少空缺，裁剪之\n",
    "data_head = 11\n",
    "data_end = 2000\n",
    "data_time = CNNdataset[\"time\"]  # [data_head:data_end]\n",
    "data_fcr = CNNdataset[\"fcr\"]  # [data_head:data_end]\n",
    "data_fcu = CNNdataset[\"fcu\"]  # [data_head:data_end]\n",
    "data_ecrl = CNNdataset[\"ecrl\"]  # [data_head:data_end]\n",
    "data_ecrb = CNNdataset[\"ecrb\"]  # [data_head:data_end]\n",
    "data_ecu = CNNdataset[\"ecu\"]  # [data_head:data_end]\n",
    "data_angle = CNNdataset[\"angle\"]  # [data_head:data_end]\n",
    "data_mf_fcr = CNNdataset[\"mf_fcr\"]  # [data_head:data_end]\n",
    "data_mf_fcu = CNNdataset[\"mf_fcu\"]  # [data_head:data_end]\n",
    "data_mf_ecrl = CNNdataset[\"mf_ecrl\"]  # [data_head:data_end]\n",
    "data_mf_ecrb = CNNdataset[\"mf_ecrb\"]  # [data_head:data_end]\n",
    "data_mf_ecu = CNNdataset[\"mf_ecu\"]  # [data_head:data_end]\n",
    "# 弧度转角度\n",
    "data_angle = data_angle / (2 * np.pi) * 360\n",
    "\n",
    "# data_time = CNNdataset['time'][data_head:data_end]\n",
    "# data_fcr= CNNdataset['fcr'][data_head:data_end]\n",
    "# data_fcu = CNNdataset['fcu'][data_head:data_end]\n",
    "# data_ecrl = CNNdataset['ecrl'][data_head:data_end]\n",
    "# data_ecrb = CNNdataset['ecrb'][data_head:data_end]\n",
    "# data_ecu = CNNdataset['ecu'][data_head:data_end]\n",
    "# data_angle = CNNdataset['angle'][data_head:data_end]\n",
    "# data_mf_fcr = CNNdataset['mf_fcr'][data_head:data_end]\n",
    "# data_mf_fcu = CNNdataset['mf_fcu'][data_head:data_end]\n",
    "# data_mf_ecrl = CNNdataset['mf_ecrl'][data_head:data_end]\n",
    "# data_mf_ecrb = CNNdataset['mf_ecrb'][data_head:data_end]\n",
    "# data_mf_ecu = CNNdataset['mf_ecu'][data_head:data_end]\n",
    "# data_angle = data_angle / (2 * np.pi) * 360\n",
    "# 划分训练集与测试集，每5点抽取一点作为测试集\n",
    "def DataSpliter(data):\n",
    "    data_tr = []\n",
    "    data_te = []\n",
    "    for i in range(len(data)):\n",
    "        if (i + 1) % 5 == 0:\n",
    "            data_te.append(data[i, :])\n",
    "        else:\n",
    "            data_tr.append(data[i, :])\n",
    "    data_tr = np.array(data_tr)\n",
    "    data_te = np.array(data_te)\n",
    "    return data_tr, data_te\n",
    "\n",
    "\n",
    "# 自变量部分\n",
    "tr_data_time, te_data_time = DataSpliter(data_time)\n",
    "tr_data_fcr, te_data_fcr = DataSpliter(data_fcr)\n",
    "tr_data_fcu, te_data_fcu = DataSpliter(data_fcu)\n",
    "tr_data_ecrl, te_data_ecrl = DataSpliter(data_ecrl)\n",
    "tr_data_ecrb, te_data_ecrb = DataSpliter(data_ecrb)\n",
    "tr_data_ecu, te_data_ecu = DataSpliter(data_ecu)\n",
    "# 因变量部分\n",
    "tr_data_angle, te_data_angle = DataSpliter(data_angle)\n",
    "tr_data_mf_fcr, te_data_mf_fcr = DataSpliter(data_mf_fcr)\n",
    "tr_data_mf_fcu, te_data_mf_fcu = DataSpliter(data_mf_fcu)\n",
    "tr_data_mf_ecrl, te_data_mf_ecrl = DataSpliter(data_mf_ecrl)\n",
    "tr_data_mf_ecrb, te_data_mf_ecrb = DataSpliter(data_mf_ecrb)\n",
    "tr_data_mf_ecu, te_data_mf_ecu = DataSpliter(data_mf_ecu)\n",
    "print(tr_data_mf_ecu.shape, te_data_ecu.shape)\n",
    "# 按需组合数据，这两函数其实可以合并成一个\n",
    "def Data_conbine(data_1, data_2, data_3, data_4, data_5, data_6):\n",
    "    data_train = []\n",
    "    for i in range(len(data_1)):\n",
    "        data_1t6 = np.hstack(\n",
    "            (\n",
    "                data_1[i, :],\n",
    "                data_2[i, :],\n",
    "                data_3[i, :],\n",
    "                data_4[i, :],\n",
    "                data_5[i, :],\n",
    "                data_6[i, :],\n",
    "            )\n",
    "        )\n",
    "        data_1t6 = data_1t6.flatten()\n",
    "        data_train.append(data_1t6)\n",
    "    data_train = np.array(data_train)\n",
    "    return data_train\n",
    "\n",
    "\n",
    "def Data_conbine_5v(data_1, data_2, data_3, data_4, data_5):\n",
    "    data_train = []\n",
    "    for i in range(len(data_1)):\n",
    "        data_1t6 = np.hstack(\n",
    "            (data_1[i, :], data_2[i, :], data_3[i, :], data_4[i, :], data_5[i, :])\n",
    "        )\n",
    "        data_1t6 = data_1t6.flatten()\n",
    "        data_train.append(data_1t6)\n",
    "    data_train = np.array(data_train)\n",
    "    return data_train\n",
    "\n",
    "\n",
    "# 多时间步组建数据，这个在这里暂时没用上，因此我把它暂时注掉了\n",
    "# def establish_multi_timestep_data(data_X,data_X_2,data_Y,expect_time_length):\n",
    "#     dataset = []\n",
    "#     dataset_y = []\n",
    "#     if expect_time_length >0:\n",
    "#         length = len(data_X)-expect_time_length\n",
    "#         for i in range(length):\n",
    "#             data_1 = data_X[i:i+expect_time_length,:]\n",
    "#             data_1 = data_1.flatten()\n",
    "#             data_2 = data_X_2[i:i+expect_time_length,:]\n",
    "#             data_2 = data_2.flatten()\n",
    "#             data_12 = np.hstack((data_1,data_2))\n",
    "#             dataset.append(data_12)\n",
    "#             dataset_y.append(data_Y[i+expect_time_length-1,:])\n",
    "#         dataset = np.array(dataset)\n",
    "#         dataset_y = np.array(dataset_y)\n",
    "#     return dataset, dataset_y\n",
    "# 将自变量与因变量各自组合到一起，尺寸均为1*6\n",
    "data_1t6_tr = Data_conbine(\n",
    "    tr_data_time, tr_data_fcr, tr_data_fcu, tr_data_ecrl, tr_data_ecrb, tr_data_ecu\n",
    ")\n",
    "data_1t6_te = Data_conbine(\n",
    "    te_data_time, te_data_fcr, te_data_fcu, te_data_ecrl, te_data_ecrb, te_data_ecu\n",
    ")\n",
    "data_7t12_tr = Data_conbine(\n",
    "    tr_data_angle,\n",
    "    tr_data_mf_fcr,\n",
    "    tr_data_mf_fcu,\n",
    "    tr_data_mf_ecrl,\n",
    "    tr_data_mf_ecrb,\n",
    "    tr_data_mf_ecu,\n",
    ")\n",
    "data_7t12_te = Data_conbine(\n",
    "    te_data_angle,\n",
    "    te_data_mf_fcr,\n",
    "    te_data_mf_fcu,\n",
    "    te_data_mf_ecrl,\n",
    "    te_data_mf_ecrb,\n",
    "    te_data_mf_ecu,\n",
    ")\n",
    "data_8t12_tr = Data_conbine_5v(\n",
    "    tr_data_mf_fcr, tr_data_mf_fcu, tr_data_mf_ecrl, tr_data_mf_ecrb, tr_data_mf_ecu\n",
    ")\n",
    "data_8t12_te = Data_conbine_5v(\n",
    "    te_data_mf_fcr, te_data_mf_fcu, te_data_mf_ecrl, te_data_mf_ecrb, te_data_mf_ecu\n",
    ")\n",
    "# 转为 tensor 格式\n",
    "data_1t6_tr = torch.from_numpy(data_1t6_tr).to(torch.float32)\n",
    "data_1t6_te = torch.from_numpy(data_1t6_te).to(torch.float32)\n",
    "data_7t12_tr = torch.from_numpy(data_7t12_tr).to(torch.float32)\n",
    "data_7t12_te = torch.from_numpy(data_7t12_te).to(torch.float32)\n",
    "\n",
    "print(data_1t6_tr.shape, data_7t12_tr.shape, data_1t6_te.shape, data_7t12_te.shape)\n",
    "\n",
    "# # 需要一个指示前一时刻的标签，居然没注意到 cyc 每五取一后不再连续了，害\n",
    "data_index_tr = np.linspace(0, 2000, 2001)\n",
    "data_index_te = np.linspace(0, 2000, 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<iterator object at 0x000001AD1FB31070>\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),  # 将图片转换为Tensor,归一化至[0,1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class EMGSK_Dataset(Dataset):\n",
    "    def __init__(self, data_x, data_y):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.transforms = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample_x = self.data_x[index, :]\n",
    "        sample_y = self.data_y[index, :]\n",
    "        # for CNN\n",
    "        sample_x = sample_x.unsqueeze(0)\n",
    "        sample_x = sample_x.numpy()\n",
    "        sample_x = self.transforms(sample_x)\n",
    "        # 一维数据用下面的这个就行\n",
    "        # emgData = torch.Tensor(emgData)\n",
    "        return sample_x, sample_y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "\n",
    "\n",
    "class EMGSK_nl_Dataset(Dataset):\n",
    "    def __init__(self, data_x, data_y, data_idx):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.data_angle = self.data_y[:, 0]\n",
    "        self.data_time = self.data_x[:, 0]\n",
    "        self.data_mf = self.data_y[:, 1:6]\n",
    "        self.data_idx = data_idx\n",
    "        self.transforms = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample_x = self.data_x[index, :]\n",
    "        sample_y = self.data_y[index, :]\n",
    "        sample_mf = self.data_mf[index, :]\n",
    "        sample_angle = self.data_angle[index]\n",
    "        sample_time = self.data_time[index]\n",
    "        sample_idx = self.data_idx[index]\n",
    "        # for CNN\n",
    "        sample_x = sample_x.unsqueeze(0)\n",
    "        sample_x = sample_x.numpy()\n",
    "        sample_x = self.transforms(sample_x)\n",
    "        # 一维数据用下面的这个就行\n",
    "        # emgData = torch.Tensor(emgData)\n",
    "        return sample_x, sample_y, sample_mf, sample_time, sample_angle, sample_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "\n",
    "\n",
    "train_set = EMGSK_nl_Dataset(data_1t6_tr, data_7t12_tr, data_index_tr)\n",
    "test_set = EMGSK_nl_Dataset(data_1t6_te, data_7t12_te, data_index_te)\n",
    "\n",
    "sample = iter(test_set)\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果展示\n",
    "展示训练效果，保存模型文件等等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (out): Linear(in_features=128, out_features=6, bias=True)\n",
       "  (dr1): Dropout2d(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = Network()\n",
    "# net2.load_state_dict(checkpoint_for_net2)\n",
    "net2.load_state_dict(checkpoint_for_net2[\"model\"])\n",
    "net2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angle: 38.253487 \n",
      " fcr: 18.214888 \n",
      " fcu: 28.10831 \n",
      " ecrl: 25.081324 \n",
      " ecrb: 22.578999 \n",
      " ecu: 1.3615419 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_x = data_1t6_te\n",
    "show_y = data_7t12_te\n",
    "show_l = 280  # 397\n",
    "column = 5\n",
    "mf_namelist = [\"angle\", \"fcr\", \"fcu\", \"ecrl\", \"ecrb\", \"ecu\"]\n",
    "net = net2\n",
    "net.eval()\n",
    "net.to(\"cpu\")\n",
    "criterion = torch.nn.MSELoss()\n",
    "# predict = net(show_x)\n",
    "# predict = predict.data.numpy()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "predict_show = []\n",
    "y_show = []\n",
    "for batch in test_loader:\n",
    "    s_x, s_y, s_mf, _, _, _ = batch\n",
    "    # s_y = s_mf\n",
    "    predict = net(s_x)\n",
    "    pred2 = predict.detach().numpy()\n",
    "    predict_show.append(pred2)\n",
    "    trainloss = criterion(predict, s_y)\n",
    "    y_s = s_y.detach().numpy()\n",
    "    y_show.append(y_s)\n",
    "predict_show = np.array(predict_show)\n",
    "y_show = np.array(y_show)\n",
    "# MSE_show = criterion(torch.Tensor(predict_show[:,column]), torch.Tensor(y_show[:,column]))\n",
    "MSE_show = criterion(\n",
    "    torch.Tensor(predict_show[:, :, column]), torch.Tensor(y_show[:, :, column])\n",
    ")\n",
    "predict = predict.data.numpy()\n",
    "print(\n",
    "    mf_namelist[0] + \":\",\n",
    "    np.std(predict_show[:, :, 0]),\n",
    "    \"\\n\",\n",
    "    mf_namelist[1] + \":\",\n",
    "    np.std(predict_show[:, :, 1]),\n",
    "    \"\\n\",\n",
    "    mf_namelist[2] + \":\",\n",
    "    np.std(predict_show[:, :, 2]),\n",
    "    \"\\n\",\n",
    "    mf_namelist[3] + \":\",\n",
    "    np.std(predict_show[:, :, 3]),\n",
    "    \"\\n\",\n",
    "    mf_namelist[4] + \":\",\n",
    "    np.std(predict_show[:, :, 4]),\n",
    "    \"\\n\",\n",
    "    mf_namelist[5] + \":\",\n",
    "    np.std(predict_show[:, :, 5]),\n",
    "    \"\\n\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# show_x = data_1t6_te\n",
    "# show_y = data_7t12_te\n",
    "# show_l = 80#397\n",
    "# column = 5\n",
    "# mf_namelist = ['angle','fcr','fcu','ecrl','ecrb','ecu']\n",
    "# # net3 = net\n",
    "# net = net2\n",
    "# net.eval()\n",
    "# net.to('cpu')\n",
    "# criterion = torch.nn.MSELoss()\n",
    "# # predict = net(show_x)\n",
    "# # predict = predict.data.numpy()\n",
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=1,shuffle=False)\n",
    "# test_loader = torch.utils.data.DataLoader(test_set, batch_size=1,shuffle=False)\n",
    "# predict_show = []\n",
    "# y_show = []\n",
    "# for batch in test_loader:\n",
    "#     s_x,s_y,s_mf,_,_,_= batch\n",
    "#     # s_y = s_mf\n",
    "#     predict = net(s_x) \n",
    "#     pred2 = predict.detach().numpy()\n",
    "#     predict_show.append(pred2) \n",
    "#     trainloss = criterion(predict, s_y)\n",
    "#     y_s = s_y.detach().numpy()\n",
    "#     y_show.append(y_s)\n",
    "# predict_show = np.array(predict_show)\n",
    "# y_show = np.array(y_show)\n",
    "# # MSE_show = criterion(torch.Tensor(predict_show[:,column]), torch.Tensor(y_show[:,column]))\n",
    "# MSE_show =  criterion(torch.Tensor(predict_show[:,:,column]), torch.Tensor(y_show[:,:,column]))\n",
    "# predict = predict.data.numpy()\n",
    "# # 建立等差数列，（起始，终止，个数）\n",
    "# x = np.linspace(1,show_l,show_l)\n",
    "# plt.rcParams['figure.dpi'] = 150\n",
    "# plt.title(mf_namelist[column]+'(RMSE:'+str('%.5g' % torch.sqrt(MSE_show))+')')\n",
    "# # plt.plot(x , show_y[:,column], label='origin')\n",
    "# plt.plot(x , show_y[:,column], label='origin')\n",
    "# # plt.plot(x, predict[:,column], color='red', label='predict')\n",
    "# plt.plot(x, predict_show[:,0,column], color='red', label='predict')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "\n",
    "adataset_kmmf = {}\n",
    "data_7t12_te = np.array(data_7t12_te)\n",
    "adataset_kmmf[\"GT\"] = data_7t12_te\n",
    "adataset_kmmf[\"Preds\"] = predict_show\n",
    "io.savemat(\"../data/data_400_mse.mat\", {\"variables\": adataset_kmmf})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 下肢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_Dir = \".//model//emgmk_cnn_0323_nl//\"\n",
    "dataarray = np.load(\n",
    "    \"../data/220319emgsk/withTrueTime/EMGSKdata-220323.npy\", allow_pickle=True\n",
    ")\n",
    "# mse\n",
    "# checkpoint_for_net2 = torch.load(model_Dir+'emgsk_lowlimb_oMSE_2022_04_26_15_28_47.pth')\n",
    "# newloss\n",
    "checkpoint_for_net2 = torch.load(\n",
    "    model_Dir + \"ckp//\" \"good_ep_1658_2022_03_29_20_14_09.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "(81, 1) (20, 1)\n",
      "(76, 10) (15, 1)\n",
      "torch.Size([20, 2]) torch.Size([81, 2]) torch.Size([81, 3])\n",
      "<iterator object at 0x000001AD7210FEE0>\n"
     ]
    }
   ],
   "source": [
    "CNNdataset = dataarray.item()\n",
    "print(type(CNNdataset))\n",
    "# 加载自变量：\n",
    "data_cyc = CNNdataset[\"data_cyc\"]\n",
    "data_emg_rf_l = CNNdataset[\"data_emg_rf_l\"]\n",
    "data_emg_lh_l = CNNdataset[\"data_emg_lh_l\"]\n",
    "data_mf_rf_l = CNNdataset[\"data_mf_rf_l\"]\n",
    "data_mf_bm_l = CNNdataset[\"data_mf_bm_l\"]\n",
    "data_ka_l = CNNdataset[\"data_ka_l\"]\n",
    "data_time = CNNdataset[\"data_time\"]\n",
    "\n",
    "# 划分训练集与测试集\n",
    "def DataSpliter(data):\n",
    "    data_tr = []\n",
    "    data_te = []\n",
    "    for i in range(len(data)):\n",
    "        if (i + 1) % 5 == 0:\n",
    "            data_te.append(data[i, :])\n",
    "        else:\n",
    "            data_tr.append(data[i, :])\n",
    "    data_tr = np.array(data_tr)\n",
    "    data_te = np.array(data_te)\n",
    "    return data_tr, data_te\n",
    "\n",
    "\n",
    "tr_cyc, te_cyc = DataSpliter(data_cyc)\n",
    "print(tr_cyc.shape, te_cyc.shape)\n",
    "tr_mf_bm_l, te_mf_bm_l = DataSpliter(data_mf_bm_l)\n",
    "tr_emg_rf_l, te_emg_rf_l = DataSpliter(data_emg_rf_l)\n",
    "tr_emg_lh_l, te_emg_lh_l = DataSpliter(data_emg_lh_l)\n",
    "tr_mf_rf_l, te_mf_rf_l = DataSpliter(data_mf_rf_l)\n",
    "tr_ka_l, te_ka_l = DataSpliter(data_ka_l)\n",
    "# 新增部分，常量的部分数据也需要跟随划分成训练集和测试集\n",
    "tr_data_time, te_data_time = DataSpliter(data_time)\n",
    "# 按需组合数据，这两函数其实可以合并成一个\n",
    "def Data_conbine(data_1, data_2):\n",
    "    data_train = []\n",
    "    for i in range(len(data_1)):\n",
    "        data_1_2 = np.hstack((data_1[i, :], data_2[i, :]))\n",
    "        data_1_2 = data_1_2.flatten()\n",
    "        data_train.append(data_1_2)\n",
    "    data_train = np.array(data_train)\n",
    "    return data_train\n",
    "\n",
    "\n",
    "def establish_multi_timestep_data(data_X, data_X_2, data_Y, expect_time_length):\n",
    "    dataset = []\n",
    "    dataset_y = []\n",
    "    if expect_time_length > 0:\n",
    "        length = len(data_X) - expect_time_length\n",
    "        for i in range(length):\n",
    "            data_1 = data_X[i : i + expect_time_length, :]\n",
    "            data_1 = data_1.flatten()\n",
    "            data_2 = data_X_2[i : i + expect_time_length, :]\n",
    "            data_2 = data_2.flatten()\n",
    "            data_12 = np.hstack((data_1, data_2))\n",
    "            dataset.append(data_12)\n",
    "            dataset_y.append(data_Y[i + expect_time_length - 1, :])\n",
    "        dataset = np.array(dataset)\n",
    "        dataset_y = np.array(dataset_y)\n",
    "    return dataset, dataset_y\n",
    "\n",
    "\n",
    "data_12_tr = Data_conbine(tr_cyc, tr_emg_rf_l)\n",
    "data_12_te = Data_conbine(te_cyc, te_emg_rf_l)\n",
    "data_13_tr = Data_conbine(tr_cyc, tr_emg_lh_l)\n",
    "data_13_te = Data_conbine(te_cyc, te_emg_lh_l)\n",
    "data_123_tr = Data_conbine(data_12_tr, tr_emg_lh_l)\n",
    "data_123_te = Data_conbine(data_12_te, te_emg_lh_l)\n",
    "data_45_tr_y = Data_conbine(tr_mf_rf_l, tr_mf_bm_l)\n",
    "data_45_te_y = Data_conbine(te_mf_rf_l, te_mf_bm_l)\n",
    "data_457_tr_y = Data_conbine(data_45_tr_y, tr_ka_l)\n",
    "data_457_te_y = Data_conbine(data_45_te_y, te_ka_l)\n",
    "\n",
    "data_13_tr_5t, data_13_tr_5t_y = establish_multi_timestep_data(\n",
    "    tr_cyc, tr_emg_lh_l, tr_mf_bm_l, 5\n",
    ")\n",
    "data_13_te_5t, data_13_te_5t_y = establish_multi_timestep_data(\n",
    "    te_cyc, te_emg_lh_l, te_mf_bm_l, 5\n",
    ")\n",
    "print(data_13_tr_5t.shape, data_13_te_5t_y.shape)\n",
    "# 转为 tensor 格式\n",
    "data_12_tr = torch.from_numpy(data_12_tr)\n",
    "data_12_te = torch.from_numpy(data_12_te)\n",
    "data_13_tr = torch.from_numpy(data_13_tr)\n",
    "data_13_te = torch.from_numpy(data_13_te)\n",
    "data_123_tr = torch.from_numpy(data_123_tr)\n",
    "data_123_te = torch.from_numpy(data_123_te)\n",
    "tr_mf_rf_l = torch.from_numpy(tr_mf_rf_l)\n",
    "te_mf_rf_l = torch.from_numpy(te_mf_rf_l)\n",
    "tr_mf_bm_l = torch.from_numpy(tr_mf_bm_l)\n",
    "te_mf_bm_l = torch.from_numpy(te_mf_bm_l)\n",
    "tr_ka_l = torch.from_numpy(tr_ka_l)\n",
    "te_ka_l = torch.from_numpy(te_ka_l)\n",
    "\n",
    "data_12_tr = data_12_tr.to(torch.float32)\n",
    "data_12_te = data_12_te.to(torch.float32)\n",
    "data_13_tr = data_13_tr.to(torch.float32)\n",
    "data_13_te = data_13_te.to(torch.float32)\n",
    "data_123_tr = data_123_tr.to(torch.float32)\n",
    "data_123_te = data_123_te.to(torch.float32)\n",
    "tr_mf_rf_l = tr_mf_rf_l.to(torch.float32)\n",
    "te_mf_rf_l = te_mf_rf_l.to(torch.float32)\n",
    "tr_mf_bm_l = tr_mf_bm_l.to(torch.float32)\n",
    "te_mf_bm_l = te_mf_bm_l.to(torch.float32)\n",
    "tr_ka_l = tr_ka_l.to(torch.float32)\n",
    "te_ka_l = te_ka_l.to(torch.float32)\n",
    "\n",
    "data_13_tr_5t = torch.from_numpy(data_13_tr_5t).to(torch.float32)\n",
    "data_13_te_5t = torch.from_numpy(data_13_te_5t).to(torch.float32)\n",
    "data_13_tr_5t_y = torch.from_numpy(data_13_tr_5t_y).to(torch.float32)\n",
    "data_13_te_5t_y = torch.from_numpy(data_13_te_5t_y).to(torch.float32)\n",
    "\n",
    "\n",
    "data_45_tr_y = torch.from_numpy(data_45_tr_y).to(torch.float32)\n",
    "data_45_te_y = torch.from_numpy(data_45_te_y).to(torch.float32)\n",
    "data_457_tr_y = torch.from_numpy(data_457_tr_y).to(torch.float32)\n",
    "data_457_te_y = torch.from_numpy(data_457_te_y).to(torch.float32)\n",
    "\n",
    "print(data_12_te.shape, data_13_tr.shape, data_123_tr.shape)\n",
    "\n",
    "# 需要一个指示前一时刻的标签，居然没注意到 cyc 每五取一后不再连续了，害\n",
    "data_index_tr = np.linspace(0, 80, 81)\n",
    "data_index_te = np.linspace(0, 19, 20)\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),  # 将图片转换为Tensor,归一化至[0,1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class EMGSK_Dataset(Dataset):\n",
    "    def __init__(\n",
    "        self, data_x, data_y, data_Ma, data_Cv, data_G_theta, data_M_Arf, data_M_Abif\n",
    "    ):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.data_Ma = data_Ma\n",
    "        self.data_Cv = data_Cv\n",
    "        self.data_G_theta = data_G_theta\n",
    "        self.data_M_Arf = data_M_Arf\n",
    "        self.data_M_Abif = data_M_Abif\n",
    "\n",
    "        self.transforms = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample_x = self.data_x[index, :]\n",
    "        sample_y = self.data_y[index, :]\n",
    "        sample_Ma = self.data_Ma[index, :]\n",
    "        sample_Cv = self.data_Cv[index, :]\n",
    "        sample_G_theta = self.data_G_theta[index, :]\n",
    "        sample_M_Arf = self.data_M_Arf[index, :]\n",
    "        sample_M_Abif = self.data_M_Abif[index, :]\n",
    "\n",
    "        # for CNN\n",
    "        sample_x = sample_x.unsqueeze(0)\n",
    "        sample_x = sample_x.numpy()\n",
    "        sample_x = self.transforms(sample_x)\n",
    "\n",
    "        # kmmf_Data = self.data_sample[index,:,:]\n",
    "        # kmmfData = np.squeeze(kmmfData)\n",
    "        # kmmf_label = self.data_label[index]\n",
    "        # kmmf_label = kmmf_label.astype(np.int16)\n",
    "        # kmmf_Data = self.transforms(kmmf_Data)\n",
    "        # kmmf_label = self.transforms(kmmf_label)\n",
    "        # 一维数据用下面的这个就行\n",
    "        # emgData = torch.Tensor(emgData)\n",
    "        return (\n",
    "            sample_x,\n",
    "            sample_y,\n",
    "            sample_Ma,\n",
    "            sample_Cv,\n",
    "            sample_G_theta,\n",
    "            sample_M_Arf,\n",
    "            sample_M_Abif,\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "\n",
    "\n",
    "class EMGSK_nl_Dataset(Dataset):\n",
    "    def __init__(self, data_x, data_y, data_time, data_idx):\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        self.data_angle = self.data_y[:, 2]\n",
    "        self.data_time = data_time\n",
    "        # self.data_M_Arf = data_M_Arf\n",
    "        # self.data_M_Abif = data_M_Abif\n",
    "        self.data_idx = data_idx\n",
    "        self.transforms = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample_x = self.data_x[index, :]\n",
    "        sample_y = self.data_y[index, :]\n",
    "        sample_cyc = self.data_x[index, 0]\n",
    "        sample_angle = self.data_angle[index]\n",
    "        sample_time = self.data_time[index, :]\n",
    "        # sample_M_Arf = self.data_M_Arf[index,:]\n",
    "        # sample_M_Abif = self.data_M_Abif[index,:]\n",
    "        sample_idx = self.data_idx[index]\n",
    "        # for CNN\n",
    "        sample_x = sample_x.unsqueeze(0)\n",
    "        sample_x = sample_x.numpy()\n",
    "        sample_x = self.transforms(sample_x)\n",
    "\n",
    "        # kmmf_Data = self.data_sample[index,:,:]\n",
    "        # kmmfData = np.squeeze(kmmfData)\n",
    "        # kmmf_label = self.data_label[index]\n",
    "        # kmmf_label = kmmf_label.astype(np.int16)\n",
    "        # kmmf_Data = self.transforms(kmmf_Data)\n",
    "        # kmmf_label = self.transforms(kmmf_label)\n",
    "        # 一维数据用下面的这个就行\n",
    "        # emgData = torch.Tensor(emgData)\n",
    "        return sample_x, sample_y, sample_angle, sample_time, sample_cyc, sample_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_x)\n",
    "\n",
    "\n",
    "train_set = EMGSK_nl_Dataset(data_123_tr, data_457_tr_y, tr_data_time, data_index_tr)\n",
    "test_set = EMGSK_nl_Dataset(data_123_te, data_457_te_y, te_data_time, data_index_te)\n",
    "\n",
    "sample = iter(test_set)\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [1, 128, 1, 3]           1,280\n",
      "            Linear-2                   [1, 128]          49,280\n",
      "            Linear-3                   [1, 128]          16,512\n",
      "            Linear-4                     [1, 3]             387\n",
      "================================================================\n",
      "Total params: 67,459\n",
      "Trainable params: 67,459\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.26\n",
      "Estimated Total Size (MB): 0.26\n",
      "----------------------------------------------------------------\n",
      "Outputshape: torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "# 自定义神经网络,CNN\n",
    "def get_num_correct(preds, labels):\n",
    "    return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=1, out_channels=128, kernel_size=3, padding=1\n",
    "        )\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, padding=1\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=32, out_channels=32, kernel_size=3, padding=0\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=128 * 1 * 3, out_features=128)\n",
    "        self.fc2 = nn.Linear(in_features=128, out_features=128)\n",
    "        # self.fc3 = nn.Linear(in_features=hdlayer_2, out_features=hdlayer_3)\n",
    "        self.out = nn.Linear(in_features=128, out_features=3)\n",
    "        self.dr1 = nn.Dropout2d(0.2)\n",
    "\n",
    "    def forward(self, t):\n",
    "        # (1) input layer\n",
    "        t = t\n",
    "\n",
    "        # (2) hidden conv layer\n",
    "        t = self.conv1(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # (3) hidden conv layer\n",
    "\n",
    "        # (4) hidden linear layer\n",
    "        t = t.reshape(-1, 128 * 1 * 3)\n",
    "        t = self.fc1(t)\n",
    "        t = F.relu(t)\n",
    "        t = self.fc2(t)\n",
    "        t = F.relu(t)\n",
    "\n",
    "        # (5) output layer\n",
    "        t = self.out(t)\n",
    "\n",
    "        return t\n",
    "\n",
    "\n",
    "net = Network()\n",
    "# 打印网络，检查输入输出 shape是否正确\n",
    "# print(net)\n",
    "samplebatchsize = 1\n",
    "summary(net, (1, 1, 3), batch_size=samplebatchsize, device=\"cpu\")\n",
    "sampleInput = torch.randn(samplebatchsize, 1, 1, 3).requires_grad_(True)\n",
    "sampleOutput = net(sampleInput)\n",
    "print(\"Outputshape:\", sampleOutput.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=384, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (out): Linear(in_features=128, out_features=3, bias=True)\n",
       "  (dr1): Dropout2d(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2 = Network()\n",
    "# net2.load_state_dict(checkpoint_for_net2)\n",
    "net2.load_state_dict(checkpoint_for_net2[\"model\"])\n",
    "net2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mf_rf: 33.87859 \n",
      " mf_bm: 142.07347 \n",
      " ka: 21.598204 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "show_x = data_123_te\n",
    "show_y = data_457_te_y\n",
    "show_l = 20\n",
    "column = 0\n",
    "mf_namelist = [\"mf_rf\", \"mf_bm\", \"ka\"]\n",
    "net = net2\n",
    "net.eval()\n",
    "net.to(\"cpu\")\n",
    "criterion = torch.nn.MSELoss()\n",
    "# predict = net(show_x)\n",
    "# predict = predict.data.numpy()\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=1, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=1, shuffle=False)\n",
    "predict_show = []\n",
    "y_show = []\n",
    "for batch in test_loader:\n",
    "    (\n",
    "        s_x,\n",
    "        s_y,\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "        _,\n",
    "    ) = batch\n",
    "    predict = net(s_x)\n",
    "    pred2 = predict.detach().numpy()\n",
    "    predict_show.append(pred2)\n",
    "    trainloss = criterion(predict, s_y)\n",
    "    y_s = s_y.detach().numpy()\n",
    "    y_show.append(y_s)\n",
    "predict_show = np.array(predict_show)\n",
    "y_show = np.array(y_show)\n",
    "# MSE_show = criterion(predict[:,column], show_y[:,column])\n",
    "MSE_show = criterion(\n",
    "    torch.Tensor(predict_show[:, :, column]), torch.Tensor(y_show[:, :, column])\n",
    ")\n",
    "predict = predict.data.numpy()\n",
    "print(\n",
    "    mf_namelist[0] + \":\",\n",
    "    np.std(predict_show[:, :, 0]),\n",
    "    \"\\n\",\n",
    "    mf_namelist[1] + \":\",\n",
    "    np.std(predict_show[:, :, 1]),\n",
    "    \"\\n\",\n",
    "    mf_namelist[2] + \":\",\n",
    "    np.std(predict_show[:, :, 2]),\n",
    "    \"\\n\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "122afd33e14e141e8feafe6109b3cf33c81901f42114774f6f58cb0f50546406"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ml2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
